#!/usr/bin/env python3

import sys
import os
import json
import time
import re
import urllib.request
import urllib.error

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
FEISHU_FILE = os.path.join(SCRIPT_DIR, "..", "assets", ".feishu")
TOKEN_CACHE = os.path.join(SCRIPT_DIR, "..", "assets", ".token_cache")
USER_TOKEN_CACHE = os.path.join(SCRIPT_DIR, "..", "assets", ".user_token_cache")
API_BASE = "https://open.feishu.cn/open-apis"


def usage():
    print(f"ç”¨æ³•: {sys.argv[0]} <action> <Feishu_URL> [content_file]")
    print()
    print("  action       æ“ä½œç±»å‹ï¼šread | write | append | clear")
    print("  Feishu_URL   é£ä¹¦æ–‡æ¡£åœ°å€ï¼Œå¦‚ https://xxx.feishu.cn/wiki/TOKEN")
    print("  content_file å†™å…¥æ—¶çš„å†…å®¹æ–‡ä»¶è·¯å¾„ï¼ˆwrite æ¨¡å¼å¿…å¡«ï¼‰")
    print()
    print("è®¤è¯æ–¹å¼ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰ï¼š")
    print("  1. user_access_tokenï¼šå…ˆè¿è¡Œ login.py æˆæƒ")
    print("  2. tenant_access_tokenï¼šåœ¨ ../assets/.feishu é…ç½® app_id + app_secret")
    sys.exit(1)


# è¯»å–é…ç½®ï¼ˆç¯å¢ƒå˜é‡ä¼˜å…ˆï¼Œ.feishu æ–‡ä»¶å…œåº•ï¼‰
def get_config(key):
    env_map = {"app_id": "FEISHU_APP_ID", "app_secret": "FEISHU_APP_SECRET"}
    env_val = os.environ.get(env_map.get(key, ""), "")
    if env_val:
        return env_val
    if not os.path.isfile(FEISHU_FILE):
        return ""
    with open(FEISHU_FILE, "r") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            if "=" in line:
                k, v = line.split("=", 1)
                k = k.strip()
                v = v.strip()
                if k == key:
                    return v
    return ""


# è·å– tenant_access_tokenï¼ˆå¸¦ç¼“å­˜ï¼Œ2å°æ—¶æœ‰æ•ˆï¼‰
def get_access_token(app_id, app_secret):
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆ1.5å°æ—¶å†…ï¼‰
    if os.path.isfile(TOKEN_CACHE):
        try:
            with open(TOKEN_CACHE, "r") as f:
                lines = f.read().strip().split("\n")
            if len(lines) >= 2:
                cached_time = int(lines[0])
                cached_token = lines[1]
                if time.time() - cached_time < 5400 and cached_token:
                    return cached_token
        except Exception:
            pass

    # è¯·æ±‚æ–° token
    req = urllib.request.Request(
        f"{API_BASE}/auth/v3/tenant_access_token/internal",
        data=json.dumps({"app_id": app_id, "app_secret": app_secret}).encode("utf-8"),
        method="POST",
    )
    req.add_header("Content-Type", "application/json")
    try:
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read().decode("utf-8"))
    except Exception as e:
        print(f"âŒ è·å– tenant_access_token å¤±è´¥: {e}", file=sys.stderr)
        return ""

    token = result.get("tenant_access_token", "")
    if not token:
        print(f"âŒ è·å– tenant_access_token å¤±è´¥: {result}", file=sys.stderr)
        return ""

    # ç¼“å­˜ token
    with open(TOKEN_CACHE, "w") as f:
        f.write(f"{int(time.time())}\n{token}\n")
    return token


# è·å– user_access_tokenï¼ˆä»ç¼“å­˜è¯»å–ï¼Œè¿‡æœŸè‡ªåŠ¨ç”¨ refresh_token åˆ·æ–°ï¼‰
def get_user_access_token(app_id, app_secret):
    if not os.path.isfile(USER_TOKEN_CACHE):
        return ""

    with open(USER_TOKEN_CACHE, "r") as f:
        cache = json.loads(f.read())

    access_token = cache.get("access_token", "")
    refresh_token = cache.get("refresh_token", "")
    expires_at = cache.get("expires_at", 0)

    # token æœªè¿‡æœŸï¼Œç›´æ¥è¿”å›ï¼ˆæå‰5åˆ†é’Ÿåˆ·æ–°ï¼‰
    if access_token and time.time() < expires_at - 300:
        return access_token

    # token è¿‡æœŸï¼Œç”¨ refresh_token åˆ·æ–°
    if not refresh_token:
        print("âŒ refresh_token ä¸ºç©ºï¼Œè¯·é‡æ–°è¿è¡Œ login.py", file=sys.stderr)
        return ""

    # å…ˆè·å– app_access_token
    req0 = urllib.request.Request(
        f"{API_BASE}/auth/v3/app_access_token/internal",
        data=json.dumps({"app_id": app_id, "app_secret": app_secret}).encode("utf-8"),
        method="POST",
    )
    req0.add_header("Content-Type", "application/json")
    try:
        with urllib.request.urlopen(req0) as resp0:
            app_token = json.loads(resp0.read().decode("utf-8")).get("app_access_token", "")
    except Exception:
        print("âŒ è·å– app_access_token å¤±è´¥", file=sys.stderr)
        return ""

    if not app_token:
        return ""

    # åˆ·æ–° user_access_token
    req = urllib.request.Request(
        f"{API_BASE}/authen/v1/oidc/refresh_access_token",
        data=json.dumps({"grant_type": "refresh_token", "refresh_token": refresh_token}).encode("utf-8"),
        method="POST",
    )
    req.add_header("Content-Type", "application/json")
    req.add_header("Authorization", f"Bearer {app_token}")

    try:
        with urllib.request.urlopen(req) as resp:
            result = json.loads(resp.read().decode("utf-8"))
    except urllib.error.HTTPError:
        print("âŒ åˆ·æ–° token å¤±è´¥ï¼Œè¯·é‡æ–°è¿è¡Œ login.py", file=sys.stderr)
        return ""

    if result.get("code", -1) != 0:
        print(f"âŒ åˆ·æ–° token å¤±è´¥: {result.get('msg', '')}ï¼Œè¯·é‡æ–°è¿è¡Œ login.py", file=sys.stderr)
        return ""

    data = result.get("data", {})
    new_access_token = data.get("access_token", "")
    new_refresh_token = data.get("refresh_token", "")
    new_expires_in = data.get("expires_in", 0)

    if not new_access_token:
        return ""

    # æ›´æ–°ç¼“å­˜
    cache["access_token"] = new_access_token
    cache["refresh_token"] = new_refresh_token
    cache["expires_at"] = int(time.time()) + new_expires_in
    with open(USER_TOKEN_CACHE, "w") as f:
        json.dump(cache, f, indent=2)

    return new_access_token


# è§£æé£ä¹¦ URL
def parse_feishu_url(url):
    if not url:
        return None
    url = url.strip()
    if not url.startswith("http"):
        url = "https://" + url

    m = re.match(r"(https?://[^/]+)/([^/]+)/([a-zA-Z0-9_-]+)", url)
    if not m:
        return None
    return m.group(1), m.group(2), m.group(3)


# è°ƒç”¨é£ä¹¦ Open API
def api_call(method, path, access_token, body=None, retries=3):
    url = f"{API_BASE}{path}"
    for attempt in range(retries):
        data = json.dumps(body).encode("utf-8") if body else None
        req = urllib.request.Request(url, data=data, method=method)
        req.add_header("Authorization", f"Bearer {access_token}")
        req.add_header("Content-Type", "application/json")
        try:
            with urllib.request.urlopen(req) as resp:
                result = json.loads(resp.read().decode("utf-8"))
                if result.get("code") == 429 and attempt < retries - 1:
                    time.sleep(2 * (attempt + 1))
                    continue
                return result
        except urllib.error.HTTPError as e:
            error_body = e.read().decode("utf-8") if e.fp else ""
            if e.code == 429 and attempt < retries - 1:
                time.sleep(2 * (attempt + 1))
                continue
            try:
                return json.loads(error_body)
            except Exception:
                return {"code": e.code, "msg": error_body}
    return {"code": 429, "msg": "rate limited after retries"}


def check_resp(resp, action_name, auto_retry_login=False):
    code = resp.get("code", -1)
    if code != 0:
        msg = resp.get("msg") or resp.get("message") or "æœªçŸ¥é”™è¯¯"
        
        # Token è¿‡æœŸæˆ–æ— æ•ˆï¼Œå°è¯•è‡ªåŠ¨ç™»å½•
        if code in (99991663, 99991664) and auto_retry_login:
            print(f"ğŸ”‘ æ£€æµ‹åˆ° Token é—®é¢˜ (code={code})ï¼Œè‡ªåŠ¨å¯åŠ¨ç™»å½•æµç¨‹...", file=sys.stderr)
            print("", file=sys.stderr)
            import subprocess
            login_script = os.path.join(SCRIPT_DIR, "login.py")
            try:
                # å…ˆé€€å‡ºç™»å½•æ¸…é™¤æ—§ token
                subprocess.run(["python3", login_script, "logout"], check=False, capture_output=True)
                # å¯åŠ¨ç™»å½•æµç¨‹ï¼ˆä¼šæ‰“å¼€æµè§ˆå™¨ï¼‰
                result = subprocess.run(["python3", login_script], check=True, capture_output=False)
                if result.returncode == 0:
                    print("", file=sys.stderr)
                    print("âœ… ç™»å½•å®Œæˆï¼Œè¯·é‡æ–°æ‰§è¡Œå‘½ä»¤", file=sys.stderr)
                    sys.exit(0)
            except subprocess.CalledProcessError:
                print("âŒ è‡ªåŠ¨ç™»å½•å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œ: python3 scripts/login.py", file=sys.stderr)
                sys.exit(1)
        
        print(f"âŒ {action_name}å¤±è´¥ (code={code}): {msg}", file=sys.stderr)
        print("", file=sys.stderr)
        if code in (99991668, 99991672, 99991679, 1770032):
            print("ğŸ“‹ æƒé™ä¸è¶³ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ’æŸ¥ï¼š", file=sys.stderr)
            print("", file=sys.stderr)
            print("   1ï¸âƒ£  ç¡®è®¤é£ä¹¦åº”ç”¨å·²å¼€é€šæƒé™", file=sys.stderr)
            print("      æ‰“å¼€ https://open.feishu.cn/app â†’ è¿›å…¥åº”ç”¨ â†’ æƒé™ç®¡ç†", file=sys.stderr)
            print("      æœç´¢å¹¶å¼€é€š: docx:document + docx:document:readonly", file=sys.stderr)
            print("", file=sys.stderr)
            print("   2ï¸âƒ£  é‡æ–°å‘å¸ƒåº”ç”¨ç‰ˆæœ¬", file=sys.stderr)
            print("      ç‰ˆæœ¬ç®¡ç†ä¸å‘å¸ƒ â†’ åˆ›å»ºç‰ˆæœ¬ â†’ æäº¤å‘å¸ƒ", file=sys.stderr)
            print("      âš ï¸ æ¯æ¬¡æ”¹æƒé™åéƒ½è¦é‡æ–°å‘å¸ƒï¼Œå¦åˆ™ä¸ç”Ÿæ•ˆ", file=sys.stderr)
            print("", file=sys.stderr)
            print("   3ï¸âƒ£  é‡æ–°æˆæƒç™»å½•", file=sys.stderr)
            print("      python3 scripts/login.py logout && python3 scripts/login.py", file=sys.stderr)
            print("", file=sys.stderr)
            print("   å¦‚æœä»ç„¶å¤±è´¥ï¼Œç¡®è®¤ä½ å¯¹è¯¥æ–‡æ¡£æœ‰ç¼–è¾‘æƒé™ï¼ˆé£ä¹¦ä¸­èƒ½æ­£å¸¸æ‰“å¼€å’Œç¼–è¾‘ï¼‰", file=sys.stderr)
        elif code == 99991663:
            print("ğŸ”‘ Token å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç™»å½•ï¼š", file=sys.stderr)
            print("   python3 scripts/login.py logout && python3 scripts/login.py", file=sys.stderr)
        elif code == 99991664:
            print("ï¿½ Token æ— æ•ˆï¼Œå¯èƒ½æœªç™»å½•æˆ–ç¼“å­˜æŸåï¼Œè¯·é‡æ–°ç™»å½•ï¼š", file=sys.stderr)
            print("   python3 scripts/login.py logout && python3 scripts/login.py", file=sys.stderr)
        else:
            print("ğŸ’¡ æ’æŸ¥å»ºè®®ï¼š", file=sys.stderr)
            print("   1. ç¡®è®¤å·²è¿è¡Œ login.py å®Œæˆæˆæƒç™»å½•", file=sys.stderr)
            print("   2. ç¡®è®¤é£ä¹¦åº”ç”¨æƒé™å·²å¼€é€šå¹¶å‘å¸ƒ", file=sys.stderr)
            print("   3. é‡æ–°ç™»å½•: python3 scripts/login.py logout && python3 scripts/login.py", file=sys.stderr)
        print("", file=sys.stderr)
        print("ğŸ“– å®Œæ•´é…ç½®æŒ‡å—: https://github.com/hanhx/feishu-doc#readme", file=sys.stderr)
        sys.exit(1)
    return resp.get("data", {})


def extract_text(elements):
    if not elements:
        return ""
    parts = []
    for el in elements:
        if isinstance(el, dict):
            tr = el.get("text_run") or {}
            parts.append(tr.get("content", ""))
            mr = el.get("mention_user") or el.get("mention_doc") or {}
            if mr:
                parts.append(mr.get("content", ""))
    return "".join(parts)


def extract_block_text(block):
    for key in block:
        if isinstance(block[key], dict) and "elements" in block[key]:
            return extract_text(block[key].get("elements", []))
    return ""


def get_block_text_by_id(block_id, block_map, visited=None):
    if visited is None:
        visited = set()
    if not block_id or block_id in visited:
        return ""
    visited.add(block_id)

    block = block_map.get(block_id, {})
    if not block:
        return ""

    # ä¼˜å…ˆå–å½“å‰å—æ–‡æœ¬ï¼›æ— æ–‡æœ¬æ—¶é€’å½’æ‹¼æ¥å­å—æ–‡æœ¬
    text = extract_block_text(block).strip()
    if text:
        return text

    child_texts = []
    for child_id in block.get("children", []) or []:
        child_text = get_block_text_by_id(child_id, block_map, visited)
        if child_text:
            child_texts.append(child_text)
    return "\n".join(child_texts)


def collect_descendant_ids(block_id, block_map, visited=None):
    if visited is None:
        visited = set()
    if not block_id or block_id in visited:
        return set()
    visited.add(block_id)

    block = block_map.get(block_id, {})
    descendants = set()
    for child_id in block.get("children", []) or []:
        descendants.add(child_id)
        descendants.update(collect_descendant_ids(child_id, block_map, visited))
    return descendants


def table_block_to_md(block, block_map):
    table = block.get("table", {})
    prop = table.get("property", {}) if isinstance(table, dict) else {}

    row_size = int(prop.get("row_size", 0) or 0)
    col_size = int(prop.get("column_size", 0) or 0)
    cell_ids = table.get("cells", []) if isinstance(table, dict) else []

    if row_size <= 0 or col_size <= 0 or not cell_ids:
        return "[è¡¨æ ¼]"

    row_count = min(row_size, max(1, len(cell_ids) // col_size))
    matrix = [["" for _ in range(col_size)] for _ in range(row_count)]

    total_cells = min(len(cell_ids), row_count * col_size)
    for idx in range(total_cells):
        r = idx // col_size
        c = idx % col_size
        text = get_block_text_by_id(cell_ids[idx], block_map).strip()
        text = text.replace("\n", "<br>").replace("|", "\\|")
        matrix[r][c] = text

    if not matrix:
        return "[è¡¨æ ¼]"

    header = matrix[0]
    separator = ["---"] * col_size
    lines = [
        "| " + " | ".join(header) + " |",
        "| " + " | ".join(separator) + " |",
    ]
    for row in matrix[1:]:
        lines.append("| " + " | ".join(row) + " |")
    return "\n".join(lines)


def callout_block_to_md(block, block_map):
    texts = []

    # ä¼˜å…ˆä»å­å—è¯»å–ï¼ˆé¿å…ä¸ elements é‡å¤ï¼‰
    children = block.get("children", []) or []
    if children:
        for child_id in children:
            child_text = get_block_text_by_id(child_id, block_map).strip()
            if child_text:
                texts.append(child_text)
    else:
        # æ— å­å—æ—¶æ‰ä» callout.elements è¯»å–
        callout = block.get("callout", {})
        if isinstance(callout, dict) and callout.get("elements"):
            direct = extract_text(callout.get("elements", [])).strip()
            if direct:
                texts.append(direct)

    if not texts:
        return None

    merged = "\n".join(texts)
    return "\n".join([f"> {ln}" if ln else ">" for ln in merged.split("\n")])


def block_to_md(block, block_map=None):
    btype = block.get("block_type", 0)
    if btype == 1:  # page
        page = block.get("page", {})
        return "# " + extract_text(page.get("elements", []))
    elif btype == 2:  # text
        return extract_text(block.get("text", {}).get("elements", []))
    elif btype in range(3, 12):  # heading 1-9
        level = btype - 2
        key = f"heading{level}"
        return "#" * level + " " + extract_text(block.get(key, {}).get("elements", []))
    elif btype == 12:  # bullet
        return "- " + extract_text(block.get("bullet", {}).get("elements", []))
    elif btype == 13:  # ordered
        return "1. " + extract_text(block.get("ordered", {}).get("elements", []))
    elif btype == 14:  # code
        code = block.get("code", {})
        lang_map = {
            0: "PlainText", 1: "ABAP", 2: "Ada", 3: "Apache", 4: "Apex", 5: "Assembly",
            6: "Bash", 7: "CSharp", 8: "CPP", 9: "C", 10: "COBOL", 11: "CSS", 12: "CoffeeScript",
            13: "D", 14: "Dart", 15: "Delphi", 16: "Django", 17: "Dockerfile", 18: "Erlang",
            19: "Fortran", 20: "FoxPro", 21: "Go", 22: "Groovy", 23: "HTML", 24: "HTMLBars",
            25: "HTTP", 26: "Haskell", 27: "JSON", 28: "Java", 29: "JavaScript", 30: "Julia",
            31: "Kotlin", 32: "LateX", 33: "Lisp", 34: "Logo", 35: "Lua", 36: "MATLAB",
            37: "Makefile", 38: "Markdown", 39: "Nginx", 40: "Objective-C", 41: "OpenEdgeABL",
            42: "PHP", 43: "Perl", 44: "PostScript", 45: "Power Shell", 46: "Prolog",
            47: "ProtoBuf", 48: "Python", 49: "R", 50: "RPG", 51: "Ruby", 52: "Rust", 53: "SAS",
            54: "SCSS", 55: "SQL", 56: "Scala", 57: "Scheme", 58: "Scratch", 59: "Shell",
            60: "Swift", 61: "Thrift", 62: "TypeScript", 63: "VBScript", 64: "Visual Basic",
            65: "XML", 66: "YAML",
        }
        lang = lang_map.get(code.get("style", {}).get("language", 0), "")
        return f"```{lang}\n{extract_text(code.get('elements', []))}\n```"
    elif btype == 15:  # quote
        return "> " + extract_text(
            block.get("quote_container", block.get("quote", {})).get("elements", [])
        )
    elif btype == 17:  # todo
        todo = block.get("todo", {})
        done = todo.get("style", {}).get("done", False)
        return f"- [{'x' if done else ' '}] " + extract_text(todo.get("elements", []))
    elif btype == 23:  # divider
        return "---"
    elif btype == 27:  # image
        return "[å›¾ç‰‡]"
    elif btype == 22 or (btype == 31 and isinstance(block.get("table"), dict)):  # table
        return table_block_to_md(block, block_map or {})
    elif btype == 18:  # bitable
        return "[å¤šç»´è¡¨æ ¼]"
    elif btype == 31:  # grid
        return "[åˆ†æ ]"
    elif btype == 19:  # callout
        return callout_block_to_md(block, block_map or {})
    else:
        return extract_block_text(block)


def parse_inline_styles(text):
    """Parse markdown inline styles into feishu text_run elements with styles."""
    if not text:
        return [{"text_run": {"content": " "}}]
    elements = []
    pattern = re.compile(
        r'(\*\*(.+?)\*\*)'           # bold
        r'|(`([^`]+)`)'              # inline code
        r'|(~~(.+?)~~)'              # strikethrough
        r'|(\[([^\]]+)\]\(([^)]+)\))'  # link
    )
    pos = 0
    for m in pattern.finditer(text):
        if m.start() > pos:
            elements.append({"text_run": {"content": text[pos:m.start()]}})
        if m.group(2):  # bold
            elements.append({"text_run": {"content": m.group(2), "text_element_style": {"bold": True}}})
        elif m.group(4):  # inline code
            elements.append({"text_run": {"content": m.group(4), "text_element_style": {"inline_code": True}}})
        elif m.group(6):  # strikethrough
            elements.append({"text_run": {"content": m.group(6), "text_element_style": {"strikethrough": True}}})
        elif m.group(8):  # link
            link_url = m.group(9)
            if link_url.startswith("http://") or link_url.startswith("https://"):
                elements.append({"text_run": {"content": m.group(8), "text_element_style": {"link": {"url": link_url}}}})
            else:
                elements.append({"text_run": {"content": f"[{m.group(8)}]({link_url})"}})
        pos = m.end()
    if pos < len(text):
        elements.append({"text_run": {"content": text[pos:]}})
    return elements if elements else [{"text_run": {"content": " "}}]


def make_text_elements(text):
    return parse_inline_styles(text)


def make_plain_elements(text):
    return [{"text_run": {"content": text}}] if text else [{"text_run": {"content": " "}}]


def make_text_block(text):
    return {"block_type": 2, "text": {"elements": make_text_elements(text)}}


def make_heading_block(level, text):
    level = max(1, min(level, 9))
    block_type = level + 2  # H1=3, H2=4, ..., H9=11
    key = f"heading{level}"
    elements = [{"text_run": {"content": text, "text_element_style": {"bold": True}}}]
    return {"block_type": block_type, key: {"elements": elements}}


def make_bullet_block(text):
    return {"block_type": 12, "bullet": {"elements": make_text_elements(text)}}


def make_ordered_block(text):
    return {"block_type": 13, "ordered": {"elements": make_text_elements(text)}}


def make_code_block(code_text, lang=""):
    lang_map = {
        "sql": 56, "java": 29, "javascript": 30, "typescript": 63, "python": 49,
        "go": 22, "bash": 7, "shell": 60, "json": 28, "yaml": 67, "xml": 66,
        "html": 24, "css": 11, "groovy": 23, "lua": 36, "markdown": 39,
        "nginx": 40, "php": 43, "c": 10, "cpp": 9, "c++": 9, "csharp": 8, "c#": 8,
        "scala": 57, "ruby": 52, "rust": 53, "r": 50, "scss": 55,
        "mermaid": 21, "plaintext": 21, "": 21,
    }
    lang_code = lang_map.get(lang.lower(), 21)
    return {
        "block_type": 14,
        "code": {
            "elements": make_plain_elements(code_text),
            "style": {"language": lang_code},
        },
    }


def make_quote_block(text):
    return {"_callout": True, "_callout_text": text}


def make_divider_block():
    return {"block_type": 2, "text": {"elements": make_text_elements("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")}}


def make_todo_block(text, done=False):
    return {
        "block_type": 17,
        "todo": {
            "elements": make_text_elements(text),
            "style": {"done": done},
        },
    }


def process(action, doc_url, access_token, doc_type, token, content_file=""):
    doc_token = token

    if action == "read":
        # è·å–çº¯æ–‡æœ¬
        resp = api_call("GET", f"/docx/v1/documents/{doc_token}/raw_content", access_token)
        data = check_resp(resp, "è·å–æ–‡æ¡£å†…å®¹", auto_retry_login=True)
        content = data.get("content", "")

        # è·å– blocks å¹¶è½¬ä¸º markdownï¼ˆæ”¯æŒç¿»é¡µï¼‰
        items = []
        page_token = ""
        while True:
            url = f"/docx/v1/documents/{doc_token}/blocks?page_size=500"
            if page_token:
                url += f"&page_token={page_token}"
            resp2 = api_call("GET", url, access_token)
            blocks_data = resp2.get("data", {}) if resp2.get("code", -1) == 0 else {}
            items.extend(blocks_data.get("items", []))
            if not blocks_data.get("has_more", False):
                break
            page_token = blocks_data.get("page_token", "")
            if not page_token:
                break

        block_map = {it.get("block_id"): it for it in items if it.get("block_id")}
        skip_block_ids = set()
        for it in items:
            btype = it.get("block_type", 0)
            # Skip table cell descendants
            is_table = btype == 22 or (btype == 31 and isinstance(it.get("table"), dict))
            if is_table:
                table = it.get("table", {})
                for cell_id in table.get("cells", []) or []:
                    skip_block_ids.add(cell_id)
                    skip_block_ids.update(collect_descendant_ids(cell_id, block_map))
            # Skip callout children to avoid duplication
            if btype == 19:
                for child_id in it.get("children", []) or []:
                    skip_block_ids.add(child_id)
                    skip_block_ids.update(collect_descendant_ids(child_id, block_map))

        md_lines = []
        for item in items:
            block_id = item.get("block_id", "")
            if block_id and block_id in skip_block_ids:
                continue
            line = block_to_md(item, block_map)
            if line is not None:
                md_lines.append(line)

        markdown = "\n".join(md_lines)
        title = ""

        out = {
            "docUrl": doc_url,
            "title": title if doc_type == "wiki" else "",
            "blockCount": len(items),
            "markdown": markdown,
            "rawContent": content,
        }
        print(json.dumps(out, ensure_ascii=False, indent=2))

    elif action == "clear":
        page_block_id = doc_token
        clear_resp = api_call("GET", f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}", access_token)
        clear_data = check_resp(clear_resp, "è·å–æ–‡æ¡£å—", auto_retry_login=True)
        clear_children = clear_data.get("block", {}).get("children", [])
        # æ¸…ç©ºæ ‡é¢˜
        api_call(
            "PATCH",
            f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}",
            access_token,
            {"update_text_elements": {"elements": [{"text_run": {"content": " "}}]}},
        )
        if not clear_children:
            out = {"docUrl": doc_url, "action": "clear", "blocksDeleted": 0, "status": "success"}
            print(json.dumps(out, ensure_ascii=False, indent=2))
        else:
            del_count = len(clear_children)
            del_resp = api_call(
                "DELETE",
                f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}/children/batch_delete",
                access_token,
                {"start_index": 0, "end_index": del_count},
            )
            if del_resp.get("code") != 0:
                remaining = del_count
                while remaining > 0:
                    batch = min(50, remaining)
                    api_call(
                        "DELETE",
                        f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}/children/batch_delete",
                        access_token,
                        {"start_index": 0, "end_index": batch},
                    )
                    remaining -= batch
                    time.sleep(0.3)
            out = {"docUrl": doc_url, "action": "clear", "blocksDeleted": del_count, "status": "success"}
            print(json.dumps(out, ensure_ascii=False, indent=2))

    elif action in ("write", "append"):
        if not content_file:
            print(f"âŒ {action} æ¨¡å¼éœ€è¦æŒ‡å®šå†…å®¹æ–‡ä»¶è·¯å¾„", file=sys.stderr)
            sys.exit(1)

        with open(content_file, "r", encoding="utf-8") as f:
            content = f.read()

        page_block_id = doc_token
        BATCH_SIZE = 50
        counter = [0]

        def flush_blocks(block_list):
            pending_buf = []
            for blk in block_list:
                if blk.get("_callout"):
                    while pending_buf:
                        batch = pending_buf[:BATCH_SIZE]
                        pending_buf = pending_buf[BATCH_SIZE:]
                        resp = api_call(
                            "POST",
                            f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}/children",
                            access_token,
                            {"children": batch, "index": -1},
                        )
                        check_resp(resp, "å†™å…¥æ–‡æ¡£", auto_retry_login=True)
                        counter[0] += len(batch)
                        time.sleep(0.5)
                    cb = {"block_type": 19, "callout": {"background_color": 15}}
                    cr = api_call(
                        "POST",
                        f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}/children",
                        access_token,
                        {"children": [cb], "index": -1},
                    )
                    cd = check_resp(cr, "åˆ›å»ºå¼•ç”¨å—", auto_retry_login=True)
                    counter[0] += 1
                    ci = cd.get("children", [{}])[0].get("block_id", "")
                    if ci:
                        cc = {"block_type": 2, "text": {"elements": make_text_elements(blk["_callout_text"])}}
                        api_call(
                            "POST",
                            f"/docx/v1/documents/{doc_token}/blocks/{ci}/children",
                            access_token,
                            {"children": [cc], "index": 0},
                        )
                    time.sleep(0.3)
                else:
                    pending_buf.append(blk)
            while pending_buf:
                batch = pending_buf[:BATCH_SIZE]
                pending_buf = pending_buf[BATCH_SIZE:]
                resp = api_call(
                    "POST",
                    f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}/children",
                    access_token,
                    {"children": batch, "index": -1},
                )
                check_resp(resp, "å†™å…¥æ–‡æ¡£", auto_retry_login=True)
                counter[0] += len(batch)
                time.sleep(0.5)

        lines = content.split("\n")
        children = []
        doc_title_set = False
        i = 0

        while i < len(lines):
            line = lines[i]

            # ç¬¬ä¸€ä¸ª H1 æ ‡é¢˜ â†’ è®¾ç½®ä¸ºæ–‡æ¡£æ ‡é¢˜ï¼ˆpage block titleï¼‰ï¼Œappend æ¨¡å¼è·³è¿‡
            if not doc_title_set and re.match(r"^#\s+(.+)", line) and not re.match(r"^##", line):
                title_text = re.match(r"^#\s+(.+)", line).group(1)
                if action == "write":
                    api_call(
                        "PATCH",
                        f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}",
                        access_token,
                        {"update_text_elements": {"elements": [{"text_run": {"content": title_text}}]}},
                    )
                else:
                    children.append(make_heading_block(1, title_text))
                doc_title_set = True
                i += 1
                continue

            # ä»£ç å—
            if line.strip().startswith("```"):
                lang = line.strip()[3:].strip()
                code_lines = []
                i += 1
                while i < len(lines) and not lines[i].strip().startswith("```"):
                    code_lines.append(lines[i])
                    i += 1
                i += 1  # skip closing ```
                code_text = "\n".join(code_lines)
                # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
                if not lang:
                    ct = code_text.strip()
                    if any(k in ct for k in ["CREATE TABLE", "ALTER TABLE", "INSERT INTO", "SELECT ", "DROP TABLE"]):
                        lang = "sql"
                    elif any(k in ct for k in ["@FeignClient", "public ", "private ", "interface ", "class ", "@Override", "@GetMapping", "@PostMapping", "import "]):
                        lang = "java"
                    elif ct.startswith("{") or ct.startswith("["):
                        lang = "json"
                    elif any(k in ct for k in ["flowchart", "sequenceDiagram", "stateDiagram", "erDiagram", "gantt"]):
                        lang = "mermaid"
                    elif any(k in ct for k in ["GET /", "POST /", "PUT /", "DELETE /"]):
                        lang = "bash"
                children.append(make_code_block(code_text, lang))
                continue

            # ç©ºè¡Œ â†’ è·³è¿‡
            if not line.strip():
                i += 1
                continue

            # åˆ†å‰²çº¿
            if re.match(r"^-{3,}$", line.strip()) or re.match(r"^\*{3,}$", line.strip()):
                children.append(make_divider_block())
                i += 1
                continue

            # æ ‡é¢˜
            hm = re.match(r"^(#{1,9})\s+(.*)", line)
            if hm:
                level = len(hm.group(1))
                children.append(make_heading_block(level, hm.group(2)))
                i += 1
                continue

            # å»æ‰å‰å¯¼ç©ºæ ¼ç”¨äºåŒ¹é…
            stripped = line.lstrip()

            # todoï¼ˆæ”¯æŒç¼©è¿›ï¼‰
            tm = re.match(r"^-\s*\[([ xX])\]\s*(.*)", stripped)
            if tm:
                done = tm.group(1).lower() == "x"
                children.append(make_todo_block(tm.group(2), done))
                i += 1
                continue

            # æ— åºåˆ—è¡¨ï¼ˆæ”¯æŒç¼©è¿›ï¼‰
            if re.match(r"^[-*+]\s+", stripped):
                text = re.sub(r"^[-*+]\s+", "", stripped)
                children.append(make_bullet_block(text))
                i += 1
                continue

            # æœ‰åºåˆ—è¡¨ï¼ˆæ”¯æŒç¼©è¿›ï¼‰
            om = re.match(r"^\d+\.\s+(.*)", stripped)
            if om:
                children.append(make_ordered_block(om.group(1)))
                i += 1
                continue

            # å¼•ç”¨ï¼ˆåˆå¹¶è¿ç»­ > è¡Œï¼‰
            if stripped.startswith("> ") or stripped == ">" or (stripped.startswith(">") and not stripped.startswith(">" * 3)):
                quote_lines = []
                while i < len(lines):
                    ql = lines[i].lstrip()
                    if ql.startswith("> "):
                        ql = ql[2:]
                    elif ql.startswith(">"):
                        ql = ql[1:]
                    else:
                        break
                    quote_lines.append(ql)
                    i += 1
                children.append(make_quote_block("\n".join(quote_lines)))
                continue

            # è¡¨æ ¼ â†’ é£ä¹¦åŸç”Ÿè¡¨æ ¼
            if stripped.startswith("|") and i + 1 < len(lines) and re.match(r"^\s*\|[\s\-:|]+\|?\s*$", lines[i + 1]):
                table_lines = []
                while i < len(lines) and lines[i].strip().startswith("|"):
                    table_lines.append(lines[i].strip())
                    i += 1
                if len(table_lines) >= 2:
                    header_cells = [c.strip() for c in table_lines[0].split("|") if c.strip()]
                    data_rows = []
                    for row_line in table_lines[2:]:
                        cells = [c.strip() for c in row_line.split("|") if c.strip()]
                        data_rows.append(cells)
                    col_size = len(header_cells)
                    row_size = 1 + len(data_rows)
                    # è®¡ç®—åˆ—å®½
                    all_rows_for_width = [header_cells] + data_rows
                    col_max_len = [0] * col_size
                    for row_cells in all_rows_for_width:
                        for ci in range(min(len(row_cells), col_size)):
                            col_max_len[ci] = max(col_max_len[ci], len(row_cells[ci]))
                    total_len = max(sum(col_max_len), 1)
                    total_width = 700
                    col_widths = [max(100, int(total_width * cl / total_len)) for cl in col_max_len]
                    # å…ˆæŠŠå½“å‰ children å†™å…¥
                    flush_blocks(children)
                    children = []
                    # å¤§è¡¨æ ¼æ‹†åˆ†ï¼šæ¯ä¸ªå­è¡¨æœ€å¤š 8 è¡Œæ•°æ® + 1 è¡Œè¡¨å¤´ = 9 è¡Œ
                    MAX_DATA_ROWS = 8
                    from concurrent.futures import ThreadPoolExecutor

                    def create_and_fill_table(h_cells, d_rows, c_size, c_widths):
                        sub_row_size = 1 + len(d_rows)
                        tb = {
                            "block_type": 31,
                            "table": {
                                "property": {
                                    "row_size": sub_row_size,
                                    "column_size": c_size,
                                    "column_width": c_widths,
                                    "header_row": True,
                                },
                            },
                        }
                        tr = api_call(
                            "POST",
                            f"/docx/v1/documents/{doc_token}/blocks/{page_block_id}/children",
                            access_token,
                            {"children": [tb], "index": -1},
                        )
                        if tr.get("code", -1) != 0:
                            print(
                                f"âš ï¸ è¡¨æ ¼åˆ›å»ºå¤±è´¥({sub_row_size}x{c_size}), fallback: {tr.get('msg', '')[:80]}",
                                file=sys.stderr,
                            )
                            return False
                        counter[0] += 1
                        tc = tr.get("data", {}).get("children", [])
                        if tc:
                            cids = tc[0].get("table", {}).get("cells", [])
                            a_rows = [h_cells] + d_rows

                            def fill_cell(args):
                                cell_id, text, is_header = args
                                el = make_plain_elements(text) if is_header else make_text_elements(text)
                                cell_block = {"block_type": 2, "text": {"elements": el}}
                                api_call(
                                    "POST",
                                    f"/docx/v1/documents/{doc_token}/blocks/{cell_id}/children",
                                    access_token,
                                    {"children": [cell_block], "index": 0},
                                )

                            tasks = []
                            for ri, rc in enumerate(a_rows):
                                for ci2 in range(c_size):
                                    cidx = ri * c_size + ci2
                                    if cidx >= len(cids):
                                        break
                                    ct = rc[ci2] if ci2 < len(rc) else ""
                                    if not ct:
                                        continue
                                    tasks.append((cids[cidx], ct, ri == 0))
                            with ThreadPoolExecutor(max_workers=5) as pool:
                                pool.map(fill_cell, tasks)
                        time.sleep(0.5)
                        return True

                    # æ‹†åˆ†æ•°æ®è¡Œ
                    for chunk_start in range(0, len(data_rows), MAX_DATA_ROWS):
                        chunk = data_rows[chunk_start:chunk_start + MAX_DATA_ROWS]
                        if not create_and_fill_table(header_cells, chunk, col_size, col_widths):
                            # fallback: æ•´ä¸ªè¡¨æ ¼ç”¨ä»£ç å—
                            children.append(make_code_block("\n".join(table_lines), "markdown"))
                            break
                continue

            # è·³è¿‡ç©ºè¡Œï¼ˆé¿å…åœ¨å¼•ç”¨å—ã€è¡¨æ ¼åå¤šå‡ºç©ºç™½å—ï¼‰
            if not line.strip():
                i += 1
                continue

            # æ™®é€šæ–‡æœ¬
            children.append(make_text_block(line))
            i += 1

        if not children and counter[0] == 0:
            print("âŒ å†…å®¹ä¸ºç©º", file=sys.stderr)
            sys.exit(1)

        # å†™å…¥æ‰€æœ‰å‰©ä½™ blocks
        flush_blocks(children)

        out = {
            "docUrl": doc_url,
            "action": "write",
            "blocksAdded": counter[0],
            "totalBatches": (len(children) + BATCH_SIZE - 1) // BATCH_SIZE,
            "status": "success",
        }
        print(json.dumps(out, ensure_ascii=False, indent=2))


# --- ä¸»é€»è¾‘ ---
def main():
    if len(sys.argv) < 3:
        usage()

    action = sys.argv[1]
    doc_url = sys.argv[2]
    content_file = sys.argv[3] if len(sys.argv) > 3 else ""

    if not doc_url:
        usage()

    if action not in ("read", "write", "append", "clear"):
        print(f"âŒ ä¸æ”¯æŒçš„æ“ä½œ: {action}ï¼Œè¯·ä½¿ç”¨ read / write / append / clear", file=sys.stderr)
        sys.exit(1)

    # è§£æ URL
    parsed = parse_feishu_url(doc_url)
    if not parsed:
        print("âŒ è¯·è¾“å…¥æ­£ç¡®çš„é£ä¹¦æ–‡æ¡£åœ°å€ï¼Œæ ¼å¼ç¤ºä¾‹ï¼š", file=sys.stderr)
        print("  https://xxx.feishu.cn/wiki/TOKEN", file=sys.stderr)
        print("  https://xxx.feishu.cn/docx/TOKEN", file=sys.stderr)
        sys.exit(1)

    domain, doc_type, token = parsed

    # è·å–å‡­è¯
    app_id = get_config("app_id")
    app_secret = get_config("app_secret")

    # å¿…é¡»ä½¿ç”¨ user_access_tokenï¼ˆä¸ªäººæˆæƒï¼‰
    if not app_id or not app_secret:
        print("âŒ æœªæ‰¾åˆ°åº”ç”¨å‡­è¯ï¼Œè¯·å…ˆå®Œæˆé…ç½®ï¼š", file=sys.stderr)
        print("", file=sys.stderr)
        print("   1ï¸âƒ£  é…ç½®åº”ç”¨å‡­è¯ï¼ˆäºŒé€‰ä¸€ï¼‰ï¼š", file=sys.stderr)
        print("      æ–¹å¼A: ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰", file=sys.stderr)
        print("        export FEISHU_APP_ID=cli_xxxx", file=sys.stderr)
        print("        export FEISHU_APP_SECRET=xxxx", file=sys.stderr)
        print("      æ–¹å¼B: ç¼–è¾‘ assets/.feishu æ–‡ä»¶", file=sys.stderr)
        print("        app_id=cli_xxxx", file=sys.stderr)
        print("        app_secret=xxxx", file=sys.stderr)
        print("", file=sys.stderr)
        print("   2ï¸âƒ£  æˆæƒç™»å½•ï¼š", file=sys.stderr)
        print("      python3 scripts/login.py", file=sys.stderr)
        print("", file=sys.stderr)
        print("   ğŸ’¡ æ²¡æœ‰ App IDï¼Ÿå‚è€ƒ: https://github.com/hanhx/feishu-doc#readme", file=sys.stderr)
        sys.exit(1)

    if not os.path.isfile(USER_TOKEN_CACHE):
        print("ğŸ”‘ æ£€æµ‹åˆ°æœªç™»å½•ï¼Œè‡ªåŠ¨å¯åŠ¨ç™»å½•æµç¨‹...", file=sys.stderr)
        print("", file=sys.stderr)
        import subprocess
        login_script = os.path.join(SCRIPT_DIR, "login.py")
        try:
            result = subprocess.run(["python3", login_script], check=True, capture_output=False)
            if result.returncode == 0:
                print("", file=sys.stderr)
                print("âœ… ç™»å½•å®Œæˆï¼Œè¯·é‡æ–°æ‰§è¡Œå‘½ä»¤", file=sys.stderr)
                sys.exit(0)
        except subprocess.CalledProcessError:
            print("âŒ è‡ªåŠ¨ç™»å½•å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œ: python3 scripts/login.py", file=sys.stderr)
            sys.exit(1)

    access_token = get_user_access_token(app_id, app_secret)
    if not access_token:
        print("ğŸ”‘ Token è·å–å¤±è´¥ï¼Œè‡ªåŠ¨å¯åŠ¨ç™»å½•æµç¨‹...", file=sys.stderr)
        print("", file=sys.stderr)
        import subprocess
        login_script = os.path.join(SCRIPT_DIR, "login.py")
        try:
            subprocess.run(["python3", login_script, "logout"], check=False, capture_output=True)
            result = subprocess.run(["python3", login_script], check=True, capture_output=False)
            if result.returncode == 0:
                print("", file=sys.stderr)
                print("âœ… ç™»å½•å®Œæˆï¼Œè¯·é‡æ–°æ‰§è¡Œå‘½ä»¤", file=sys.stderr)
                sys.exit(0)
        except subprocess.CalledProcessError:
            print("âŒ è‡ªåŠ¨ç™»å½•å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œ: python3 scripts/login.py", file=sys.stderr)
            sys.exit(1)

    # æ‰§è¡Œæ“ä½œ
    process(action, doc_url, access_token, doc_type, token, content_file)


if __name__ == "__main__":
    main()
